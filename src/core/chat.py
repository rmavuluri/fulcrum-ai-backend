from typing import List, Tuple
from mcp.types import Prompt, PromptMessage
from anthropic.types import MessageParam

from src.core.claude import Claude
from src.mcp_client import MCPClient
from src.core.tools import ToolManager, WEB_SEARCH_SCHEMA


def convert_prompt_message_to_message_param(
    prompt_message: "PromptMessage",
) -> MessageParam:
    role = "user" if prompt_message.role == "user" else "assistant"
    content = prompt_message.content

    if isinstance(content, dict) or hasattr(content, "__dict__"):
        content_type = (
            content.get("type", None)
            if isinstance(content, dict)
            else getattr(content, "type", None)
        )
        if content_type == "text":
            content_text = (
                content.get("text", "")
                if isinstance(content, dict)
                else getattr(content, "text", "")
            )
            return {"role": role, "content": content_text}

    if isinstance(content, list):
        text_blocks = []
        for item in content:
            if isinstance(item, dict) or hasattr(item, "__dict__"):
                item_type = (
                    item.get("type", None)
                    if isinstance(item, dict)
                    else getattr(item, "type", None)
                )
                if item_type == "text":
                    item_text = (
                        item.get("text", "")
                        if isinstance(item, dict)
                        else getattr(item, "text", "")
                    )
                    text_blocks.append({"type": "text", "text": item_text})
        if text_blocks:
            return {"role": role, "content": text_blocks}

    return {"role": role, "content": ""}


def convert_prompt_messages_to_message_params(
    prompt_messages: List[PromptMessage],
) -> List[MessageParam]:
    return [
        convert_prompt_message_to_message_param(msg) for msg in prompt_messages
    ]


class Chat:
    def __init__(
        self,
        claude_service: Claude,
        clients: dict[str, MCPClient],
        doc_client: MCPClient | None = None,
    ):
        self.claude_service: Claude = claude_service
        self.clients: dict[str, MCPClient] = clients
        self.doc_client: MCPClient | None = doc_client
        self.messages: list[MessageParam] = []

    async def list_prompts(self) -> list[Prompt]:
        if self.doc_client is None:
            return []
        return await self.doc_client.list_prompts()

    async def list_docs_ids(self) -> list[str]:
        if self.doc_client is None:
            return []
        return await self.doc_client.read_resource("docs://documents")

    async def get_doc_content(self, doc_id: str) -> str:
        if self.doc_client is None:
            return ""
        return await self.doc_client.read_resource(f"docs://documents/{doc_id}")

    async def get_prompt(self, command: str, doc_id: str) -> list[PromptMessage]:
        if self.doc_client is None:
            return []
        return await self.doc_client.get_prompt(command, {"doc_id": doc_id})

    async def _extract_resources(self, query: str) -> str:
        if self.doc_client is None:
            return ""
        mentions = [word[1:] for word in query.split() if word.startswith("@")]
        doc_ids = await self.list_docs_ids()
        mentioned_docs: list[Tuple[str, str]] = []
        for doc_id in doc_ids:
            if doc_id in mentions:
                content = await self.get_doc_content(doc_id)
                mentioned_docs.append((doc_id, content))
        return "".join(
            f'\n<document id="{doc_id}">\n{content}\n</document>\n'
            for doc_id, content in mentioned_docs
        )

    async def _process_command(self, query: str) -> bool:
        if self.doc_client is None or not query.startswith("/"):
            return False
        words = query.split()
        command = words[0].replace("/", "")
        if len(words) < 2:
            return False
        messages = await self.doc_client.get_prompt(command, {"doc_id": words[1]})
        self.messages += convert_prompt_messages_to_message_params(messages)
        return True

    async def _process_query(self, query: str) -> None:
        if await self._process_command(query):
            return
        added_resources = await self._extract_resources(query)
        prompt = f"""
The user has a question:
<query>
{query}
</query>

The following context may be useful in answering their question:
<context>
{added_resources}
</context>

Note the user's query might contain references to documents like "@report.docx". The "@" is only
included as a way of mentioning the doc. The actual name of the document would be "report.docx".
If the document content is included in this prompt, you don't need to use an additional tool to read the document.
Answer the user's question directly and concisely. Start with the exact information they need.
Don't refer to or mention the provided context in any way - just use it to inform your answer.
"""
        self.messages.append({"role": "user", "content": prompt})

    async def run(self, query: str) -> str:
        final_text_response = ""
        await self._process_query(query)

        while True:
            mcp_tools = await ToolManager.get_all_tools(self.clients)
            tools = [WEB_SEARCH_SCHEMA] + mcp_tools
            response = self.claude_service.chat(
                messages=self.messages,
                tools=tools,
            )
            self.claude_service.add_assistant_message(self.messages, response)

            if response.stop_reason == "tool_use":
                print(self.claude_service.text_from_message(response))
                tool_result_parts = await ToolManager.execute_tool_requests(
                    self.clients, response
                )
                self.claude_service.add_user_message(
                    self.messages, tool_result_parts
                )
            else:
                final_text_response = self.claude_service.text_from_message(
                    response
                )
                break

        return final_text_response
